---
permalink: /
title: "About"
excerpt: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I'm Kyle, a MSCS Candidate at Fordham University being advised by [Dr. Ruhul Amin](https://www.fordham.edu/academics/research/faculty-research/research-consortium-on-disability/affiliates/ruhul-amin/) as I complete my thesis in the Fordham Human Centered AI Lab. I have also recently initiated new research in the Fordham Dependable and Secure System Lab with [Dr. Zakirul Alam Bhuiyan](https://storm.cis.fordham.edu/~bhuiyan/?_ga=2.28872252.1465687045.1661225584-1927066685.1661135573).

How can we deliver on the promise of the benefits of artificial intelligence but address these scenarios that have life-critical consequences for people and society? Artificial intelligence controls the administration of insulin to help diabetics control their blood sugar levels, manages the candidate screening for the companies worldwide, and assists the judges in our courts to make more consistent rulings. The use cases of artificial intelligence are endless and are considered to be a major force in dealing with the challenges of the current Information Age. However, the more we integrate artificial intelligence into our society, the more important it becomes to guarantee that they are: robust, ethical, and reliable. Inspired by solving these problems, I hope to see improvements in the trustworthiness and safety of artificial intelligence. With the above broad goals in mind, I am currently applying to pursue a PhD in Computer Science (Fall 2023).

Trustworthy & Safe AI
======
Technologies such as GPT-3 have demonstrated profound abilities in natural language understanding and generation like its predecessors. However, more fascinating is GPT-3's ability to learn how to follow directions and learn new tasks from a small set of examples. This progress is in great part due to the exponential rise in the amount of compute resources used in the training of large language models, with the number doubling everything 3.4 months. This is not necessarily a bad thing as artificial intelligence has proven to be an incredibly valuable and beneficial tool, however, we must remain cognizant of the risks posed by scaling on a Moore's law-esque rate. Issues we see with large language models today such as biased predictions or catastrophic errors, when deployed irresponsibly, will only be amplified if AI progress is accelerated without in-depth understanding of how the system works. 

Interests
------
If you are interested, you can find my hobbies [here](https://kylejryan.github.io/hobbies/).